{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4 Fine-tuning keras models.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMzo0S1uYtQvC+EoiixkjMc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/villafue/Machine_Learning_Notes/blob/master/Deep%20Learning/DataCamp/Introduction%20to%20Deep%20Learning%20in%20Python/4%20Fine-tuning%20keras%20models/4_Fine_tuning_keras_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMNTrWWKX_84"
      },
      "source": [
        "# Fine-tuning keras models\r\n",
        "\r\n",
        "Learn how to optimize your deep learning models in Keras. Start by learning how to validate your models, then understand the concept of model capacity, and finally, experiment with wider and deeper networks. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG7_rhlzZInT"
      },
      "source": [
        "# Understanding model optimization\r\n",
        "\r\n",
        "1. Understanding model optimization\r\n",
        "\r\n",
        "At this point, you have a good understanding of how neural networks work, and how to build them in Keras. But you probably don't yet have a great intuition for how to choose things like model architecture and model optimization arguments. You'll learn that in this last chapter.\r\n",
        "2. Why optimization is hard\r\n",
        "\r\n",
        "In practice, optimization is a hard problem. The optimal value for any one weight depends on the values of the other weights, and we are optimizing many weights at once. Even if the slope tells us which weights to increase, and which to decrease, our updates may not improve our model meaningfully. A small learning rate might cause us to make such small updates to the model's weights that our model doesn't improve materially. A very large learning rate might take us too far in the direction that seemed good. A smart optimizer like Adam helps, but optimization problems can still occur. The easiest way to see the effect of different learning rates is to use the simplest optimizer,\r\n",
        "3. Stochastic gradient descent\r\n",
        "\r\n",
        "Stochastic Gradient Descent, sometimes abbreviated to SGD. This optimizer uses a fixed learning rate. Learning rates around point-01 are common. But you can specify the learning rate you need with lr argument as shown here. We have a function that creates a new model here. We create models in a for loop, and each time around we compile the model using SGD with a different learning rate. We pass in the optimizer with the same argument where we previously passed the string for \"Adam\". In an exercise, you will compare the results of training models trained with low, medium and high learning rates. Even if your learning rate is well tuned, you can run into the so-called\r\n",
        "4. The dying neuron problem\r\n",
        "\r\n",
        "\"dying-neuron\" problem. This problem occurs when a neuron takes a value less than 0 for all rows of your data. Recall that, with the ReLU activation function, any node with a negative input value produces an output of 0, and it also has a slope of 0 as you see in this graph. Because the slope is 0, the slope of any weights flowing into that node are also 0. So those weights don't get updated. In other words, once the node starts always getting negative inputs, it may continue only getting negative inputs. It's contributing nothing to the model at this point, and hence the claim that the node or neuron is \"dead.\"At first, this might suggest using an activation function whose slope is never exactly zero. However, those types of functions were used for many years.\r\n",
        "5. Vanishing gradients\r\n",
        "\r\n",
        "For example, in an earlier video we used an s-shaped function called tanh. However, values that were outside the middle of the S were\r\n",
        "6. Vanishing gradients\r\n",
        "\r\n",
        "relatively flat, or had small slopes. A small but non-zero slope might work in a network with only a few hidden layers. But in a deep network, one with many layers, the repeated multiplication of small slopes causes the slopes to get close to 0, which meant updates in backprop were close to 0. This is called the vanishing gradient problem. This in turn might suggest using an activation function that isn't even close to flat anywhere. There is research in this area, including variations on ReLU. Those aren't widely used though. For now, it's a phenomenon worth keeping in mind if you are ever pondering why your model isn't training better. If it happens, changing the activation function may be the solution. -\r\n",
        "7. Let's practice!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51Wlc3AfZOlN"
      },
      "source": [
        "# Diagnosing optimization problems\r\n",
        "\r\n",
        "Which of the following could prevent a model from showing an improved loss in its first few epochs?\r\n",
        "\r\n",
        "Possible Answers\r\n",
        "\r\n",
        "1. Learning rate too low.\r\n",
        " - Incorrect - A learning rate that is too low could indeed prevent a model from showing an improved loss in its first few epochs, but this is not the only correct option.\r\n",
        "\r\n",
        "2. Learning rate too high.\r\n",
        " - Incorrect - You are correct that a very high learning rate could prevent a model from showing an improved loss in its first few epochs, but this is not the only correct option.\r\n",
        "\r\n",
        "3. Poor choice of activation function.\r\n",
        " - Yes, a poor choice of activation function could prevent a model from showing an improved loss in its first few epochs. What about the learning rates?\r\n",
        "\r\n",
        "4. All of the above.\r\n",
        " - Correct - Well done! All the options listed could prevent a model from showing an improved loss in its first few epochs.'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ei_s3dDGfMN1"
      },
      "source": [
        "# Changing optimization parameters\r\n",
        "\r\n",
        "It's time to get your hands dirty with optimization. You'll now try optimizing a model at a very low learning rate, a very high learning rate, and a \"just right\" learning rate. You'll want to look at the results after running this exercise, remembering that a low value for the loss function is good.\r\n",
        "\r\n",
        "For these exercises, we've pre-loaded the predictors and target values from your previous classification models (predicting who would survive on the Titanic). You'll want the optimization to start from scratch every time you change the learning rate, to give a fair comparison of how each learning rate did in your results. So we have created a function get_new_model() that creates an unoptimized model to optimize.\r\n",
        "\r\n",
        "Instructions\r\n",
        "\r\n",
        "1. Import SGD from keras.optimizers.\r\n",
        "\r\n",
        "2. Create a list of learning rates to try optimizing with called lr_to_test. The learning rates in it should be .000001, 0.01, and 1.\r\n",
        "    \r\n",
        "3. Using a for loop to iterate over lr_to_test:\r\n",
        "\r\n",
        " - Use the get_new_model() function to build a new, unoptimized model.\r\n",
        "\r\n",
        " - Create an optimizer called my_optimizer using the SGD() constructor with keyword argument lr=lr.\r\n",
        "\r\n",
        " - Compile your model. Set the optimizer parameter to be the SGD object you created above, and because this is a classification problem, use 'categorical_crossentropy' for the loss parameter.\r\n",
        "\r\n",
        " - Fit your model using the predictors and target.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFgpDr5WF6yU"
      },
      "source": [
        "In [1]:\r\n",
        "get_new_model??\r\n",
        "Signature: get_new_model(input_shape=(10,))\r\n",
        "Source:\r\n",
        "def get_new_model(input_shape = input_shape):\r\n",
        "    model = Sequential()\r\n",
        "    model.add(Dense(100, activation='relu', input_shape = input_shape))\r\n",
        "    model.add(Dense(100, activation='relu'))\r\n",
        "    model.add(Dense(2, activation='softmax'))\r\n",
        "    return(model)\r\n",
        "\r\n",
        "File:      /tmp/tmpcv2_nab1/<ipython-input-1-d515abca99e9>\r\n",
        "Type:      function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnhouKi6gV4k"
      },
      "source": [
        "# Import the SGD optimizer\r\n",
        "from keras.optimizers import SGD\r\n",
        "\r\n",
        "# Create list of learning rates: lr_to_test\r\n",
        "lr_to_test = [0.000001, 0.01, 1.0]\r\n",
        "\r\n",
        "# Loop over learning rates\r\n",
        "for lr in lr_to_test:\r\n",
        "    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\r\n",
        "    \r\n",
        "    # Build new model to test, unaffected by previous models\r\n",
        "    model = get_new_model()\r\n",
        "    \r\n",
        "    # Create SGD optimizer with specified learning rate: my_optimizer\r\n",
        "    my_optimizer = SGD(lr=lr)\r\n",
        "    \r\n",
        "    # Compile the model\r\n",
        "    model.compile(optimizer = my_optimizer, loss = 'categorical_crossentropy')\r\n",
        "    \r\n",
        "    # Fit the model\r\n",
        "    model.fit(predictors, target)\r\n",
        "\r\n",
        "'''\r\n",
        "<script.py> output:\r\n",
        "    \r\n",
        "    \r\n",
        "    Testing model with learning rate: 0.000001\r\n",
        "    \r\n",
        "    Epoch 1/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 3.6053\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "672/891 [=====================>........] - ETA: 0s - loss: 3.6398\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 3.6057     \r\n",
        "    Epoch 2/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 3.5751\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "416/891 [=============>................] - ETA: 0s - loss: 3.6402\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 3.5656     \r\n",
        "    Epoch 3/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 2.6692\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "672/891 [=====================>........] - ETA: 0s - loss: 3.4949\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 3.5255     \r\n",
        "    Epoch 4/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 3.0058\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "672/891 [=====================>........] - ETA: 0s - loss: 3.4932\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 3.4854     \r\n",
        "    Epoch 5/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 2.5452\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "448/891 [==============>...............] - ETA: 0s - loss: 3.5022\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 3.4454     \r\n",
        "    Epoch 6/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 3.4446\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "768/891 [========================>.....] - ETA: 0s - loss: 3.4073\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 3.4056     \r\n",
        "    Epoch 7/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 4.1073\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "800/891 [=========================>....] - ETA: 0s - loss: 3.4131\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 3.3659     \r\n",
        "    Epoch 8/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 3.0972\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "768/891 [========================>.....] - ETA: 0s - loss: 3.2904\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 3.3263     \r\n",
        "    Epoch 9/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 3.7464\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "800/891 [=========================>....] - ETA: 0s - loss: 3.2714\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 3.2867     \r\n",
        "    Epoch 10/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 3.3862\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "736/891 [=======================>......] - ETA: 0s - loss: 3.1780\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 3.2473     \r\n",
        "    \r\n",
        "    \r\n",
        "    Testing model with learning rate: 0.010000\r\n",
        "    \r\n",
        "    Epoch 1/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 1s - loss: 1.0910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "640/891 [====================>.........] - ETA: 0s - loss: 1.6905\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 1.4069     \r\n",
        "    Epoch 2/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 2.1145\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "576/891 [==================>...........] - ETA: 0s - loss: 0.7433\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 0.7036     \r\n",
        "    Epoch 3/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 0.5716\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "704/891 [======================>.......] - ETA: 0s - loss: 0.6517\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 0.6469     \r\n",
        "    Epoch 4/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 0.6275\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "416/891 [=============>................] - ETA: 0s - loss: 0.6474\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "800/891 [=========================>....] - ETA: 0s - loss: 0.6265\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 0.6185     \r\n",
        "    Epoch 5/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 0.5038\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "512/891 [================>.............] - ETA: 0s - loss: 0.6069\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 0.6255     \r\n",
        "    Epoch 6/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 0.6622\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "512/891 [================>.............] - ETA: 0s - loss: 0.6041\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 0.5998     \r\n",
        "    Epoch 7/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 0.6197\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "736/891 [=======================>......] - ETA: 0s - loss: 0.6005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 0.5974     \r\n",
        "    Epoch 8/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 0.6083\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "544/891 [=================>............] - ETA: 0s - loss: 0.5818\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 0.6040     \r\n",
        "    Epoch 9/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 0.6553\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "704/891 [======================>.......] - ETA: 0s - loss: 0.5909\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 0.5907     \r\n",
        "    Epoch 10/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 0.6393\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "672/891 [=====================>........] - ETA: 0s - loss: 0.5783\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 0.5824     \r\n",
        "    \r\n",
        "    \r\n",
        "    Testing model with learning rate: 1.000000\r\n",
        "    \r\n",
        "    Epoch 1/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 1s - loss: 1.0273\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "384/891 [===========>..................] - ETA: 0s - loss: 5.3744\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "704/891 [======================>.......] - ETA: 0s - loss: 5.7018\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 5.9885     \r\n",
        "    Epoch 2/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 4.5332\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "512/891 [================>.............] - ETA: 0s - loss: 6.0128\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 6.1867     \r\n",
        "    Epoch 3/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 7.0517\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "416/891 [=============>................] - ETA: 0s - loss: 5.9280\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "832/891 [===========================>..] - ETA: 0s - loss: 6.2380\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 6.1867     \r\n",
        "    Epoch 4/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 6.0443\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "480/891 [===============>..............] - ETA: 0s - loss: 6.2793\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 6.1867     \r\n",
        "    Epoch 5/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 9.0664\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "576/891 [==================>...........] - ETA: 0s - loss: 6.0723\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 6.1867     \r\n",
        "    Epoch 6/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 6.0443\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "448/891 [==============>...............] - ETA: 0s - loss: 6.3681\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 6.1867     \r\n",
        "    Epoch 7/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 5.0369\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "416/891 [=============>................] - ETA: 0s - loss: 6.5480\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "768/891 [========================>.....] - ETA: 0s - loss: 6.2122\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 6.1867     \r\n",
        "    Epoch 8/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 5.0369\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "416/891 [=============>................] - ETA: 0s - loss: 5.8893\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "832/891 [===========================>..] - ETA: 0s - loss: 6.1993\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 6.1867     \r\n",
        "    Epoch 9/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 5.5406\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "416/891 [=============>................] - ETA: 0s - loss: 6.1993\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "704/891 [======================>.......] - ETA: 0s - loss: 6.0672\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 6.1867     \r\n",
        "    Epoch 10/10\r\n",
        "    \r\n",
        " 32/891 [>.............................] - ETA: 0s - loss: 5.5406\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "352/891 [==========>...................] - ETA: 0s - loss: 6.5938\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "768/891 [========================>.....] - ETA: 0s - loss: 6.0863\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "891/891 [==============================] - 0s - loss: 6.1867 \r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0UI8PgLgWmN"
      },
      "source": [
        "# Model validation\r\n",
        "\r\n",
        "1. Model validation\r\n",
        "\r\n",
        "You may recall from previous machine learning classes that your model's performance on the training data is not a good indication of how it will perform on new data. For this reason, we use validation data to test model performance. Validation data is data that is explicitly held out from training, and used only to test model performance.\r\n",
        "2. Validation in deep learning\r\n",
        "\r\n",
        "You may already be familiar with k-fold cross validation. In practice, few people run k-fold cross validation on deep learning models because deep learning is typically used on large datasets. So the computational expense of running k-fold validation would be large, and we usually trust a score from a single validation run because those validation runs are reasonably large. Keras makes it easy to use some of your data as validation data, and we see that\r\n",
        "3. Model validation\r\n",
        "\r\n",
        "in this code, where we specify the split using the keyword argument validation_split when calling the fit method. Here, we have already specified a model, and we'll make small changes in both the compile and fit steps to see model validation information. This is a classification problem, and we'd like to see measures of accuracy. So, we include metrics equals 'accuracy' in the compile step. In the fit step, we specify what fraction of the data is used for validation. In this case, we'll use 30%.Our goal is to have the best validation score possible, so we should keep training while validation score is improving, and then stop training when the validation score isn't improving. We do this with something called\r\n",
        "4. Early Stopping\r\n",
        "\r\n",
        "\"early stopping.\" We can use early stopping with only some small changes to the code. See here, we've imported something called EarlyStopping. We then create an \"early stopping monitor\" before fitting the model. That monitor takes an argument called patience, which is how many epochs the model can go without improving before we stop training. 2 or 3 are reasonable values for patience. Sometimes you'll get a single epoch with no improvement, but the model will start improving again after that epoch. But if you see 3 epochs with no improvement, it's unlikely to turn around and start improving again. We pass early_stopping_monitor to the fit function under an argument called callbacks. Notice that callbacks takes a list. You may consider adding other callbacks as you become very advanced. But early stopping is all you want for now. By default, keras trains for 10 epochs. Now that we have smart logic for determining when to stop, we can set a high maximum number of epochs. This happens with the nb_epoch argument, as you see here. Keras will go until this number of epochs, unless the validation loss stops improving, in which case it will stop earlier. This is smarter training logic than relying on a fixed number of epochs without looking at the validation scores.\r\n",
        "5. Output from early stopping\r\n",
        "\r\n",
        "Let's look at the output. In epoch 9 we had a validation loss score of point-6513. We didn't beat that score in the next 2 epochs, so we stopped training. Now that you have a reliable way of measuring model performance, namely through scores, you should feel free\r\n",
        "6. Experimentation\r\n",
        "\r\n",
        "to experiment with different architectures. More layers, fewer layers. Layers with more nodes, layers with fewer nodes. And so on. Creating a great model requires some experimentation. Before we finish, we'll give a little bit of insight into how to choose where you experiment. -\r\n",
        "7. Let's practice!\r\n",
        "\r\n",
        "But, now that you can get validation scores, you are poised to run those experiments and figure out what works best for your data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gv7cqF1-kCFd"
      },
      "source": [
        "# Evaluating model accuracy on validation dataset\r\n",
        "\r\n",
        "Now it's your turn to monitor model accuracy with a validation data set. A model definition has been provided as model. Your job is to add the code to compile it and then fit it. You'll check the validation score in each epoch.\r\n",
        "\r\n",
        "Instructions\r\n",
        "\r\n",
        "1. Compile your model using 'adam' as the optimizer and 'categorical_crossentropy' for the loss. To see what fraction of predictions are correct (the accuracy) in each epoch, specify the additional keyword argument metrics=['accuracy'] in model.compile().\r\n",
        "\r\n",
        "2. Fit the model using the predictors and target. Create a validation split of 30% (or 0.3). This will be reported in each epoch.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx4sBVr_lzYF"
      },
      "source": [
        "# Save the number of columns in predictors: n_cols\r\n",
        "n_cols = predictors.shape[1]\r\n",
        "input_shape = (n_cols,)\r\n",
        "\r\n",
        "# Specify the model\r\n",
        "model = Sequential()\r\n",
        "model.add(Dense(100, activation='relu', input_shape = input_shape))\r\n",
        "model.add(Dense(100, activation='relu'))\r\n",
        "model.add(Dense(2, activation='softmax'))\r\n",
        "\r\n",
        "# Compile the model\r\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "# Fit the model\r\n",
        "hist = model.fit(predictors, target, validation_split=0.3)\r\n",
        "\r\n",
        "'''\r\n",
        "<script.py> output:\r\n",
        "    Train on 623 samples, validate on 268 samples\r\n",
        "    Epoch 1/10\r\n",
        "    \r\n",
        " 32/623 [>.............................] - ETA: 1s - loss: 3.3028 - acc: 0.4062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "416/623 [===================>..........] - ETA: 0s - loss: 1.4013 - acc: 0.5601\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "623/623 [==============================] - 0s - loss: 1.2788 - acc: 0.5987 - val_loss: 0.6316 - val_acc: 0.7052\r\n",
        "    Epoch 2/10\r\n",
        "    \r\n",
        " 32/623 [>.............................] - ETA: 0s - loss: 0.6426 - acc: 0.7188\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "623/623 [==============================] - 0s - loss: 0.6683 - acc: 0.6517 - val_loss: 0.5947 - val_acc: 0.7239\r\n",
        "    Epoch 3/10\r\n",
        "    \r\n",
        " 32/623 [>.............................] - ETA: 0s - loss: 0.6040 - acc: 0.6875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "512/623 [=======================>......] - ETA: 0s - loss: 0.6693 - acc: 0.6309\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "623/623 [==============================] - 0s - loss: 0.6540 - acc: 0.6485 - val_loss: 0.5452 - val_acc: 0.7388\r\n",
        "    Epoch 4/10\r\n",
        "    \r\n",
        " 32/623 [>.............................] - ETA: 0s - loss: 0.5460 - acc: 0.7812\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "416/623 [===================>..........] - ETA: 0s - loss: 0.5996 - acc: 0.6923\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "623/623 [==============================] - 0s - loss: 0.6218 - acc: 0.6726 - val_loss: 0.6450 - val_acc: 0.7052\r\n",
        "    Epoch 5/10\r\n",
        "    \r\n",
        " 32/623 [>.............................] - ETA: 0s - loss: 0.6110 - acc: 0.6562\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "352/623 [===============>..............] - ETA: 0s - loss: 0.7316 - acc: 0.6392\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "623/623 [==============================] - 0s - loss: 0.8187 - acc: 0.6292 - val_loss: 0.6582 - val_acc: 0.6418\r\n",
        "    Epoch 6/10\r\n",
        "    \r\n",
        " 32/623 [>.............................] - ETA: 0s - loss: 0.6183 - acc: 0.6250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "448/623 [====================>.........] - ETA: 0s - loss: 0.6924 - acc: 0.6004\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "623/623 [==============================] - 0s - loss: 0.6758 - acc: 0.6196 - val_loss: 0.5180 - val_acc: 0.7537\r\n",
        "    Epoch 7/10\r\n",
        "    \r\n",
        " 32/623 [>.............................] - ETA: 0s - loss: 0.5324 - acc: 0.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "448/623 [====================>.........] - ETA: 0s - loss: 0.6122 - acc: 0.6875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "623/623 [==============================] - 0s - loss: 0.5968 - acc: 0.6934 - val_loss: 0.5050 - val_acc: 0.7239\r\n",
        "    Epoch 8/10\r\n",
        "    \r\n",
        " 32/623 [>.............................] - ETA: 0s - loss: 0.6103 - acc: 0.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "448/623 [====================>.........] - ETA: 0s - loss: 0.5754 - acc: 0.7165\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "623/623 [==============================] - 0s - loss: 0.5911 - acc: 0.6902 - val_loss: 0.5295 - val_acc: 0.7425\r\n",
        "    Epoch 9/10\r\n",
        "    \r\n",
        " 32/623 [>.............................] - ETA: 0s - loss: 0.5686 - acc: 0.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "512/623 [=======================>......] - ETA: 0s - loss: 0.7069 - acc: 0.6582\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "623/623 [==============================] - 0s - loss: 0.7084 - acc: 0.6613 - val_loss: 0.6349 - val_acc: 0.6866\r\n",
        "    Epoch 10/10\r\n",
        "    \r\n",
        " 32/623 [>.............................] - ETA: 0s - loss: 0.4938 - acc: 0.7812\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "608/623 [============================>.] - ETA: 0s - loss: 0.6252 - acc: 0.6941\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "623/623 [==============================] - 0s - loss: 0.6213 - acc: 0.6966 - val_loss: 0.5357 - val_acc: 0.7500\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml2dJfq3l9KK"
      },
      "source": [
        "# Early stopping: Optimizing the optimization\r\n",
        "\r\n",
        "Now that you know how to monitor your model performance throughout optimization, you can use early stopping to stop optimization when it isn't helping any more. Since the optimization stops automatically when it isn't helping, you can also set a high value for epochs in your call to .fit(), as Dan showed in the video.\r\n",
        "\r\n",
        "The model you'll optimize has been specified as model. As before, the data is pre-loaded as predictors and target.\r\n",
        "\r\n",
        "Instructions\r\n",
        "\r\n",
        "1. Import EarlyStopping from keras.callbacks.\r\n",
        "\r\n",
        "2. Compile the model, once again using 'adam' as the optimizer, 'categorical_crossentropy' as the loss function, and metrics=['accuracy'] to see the accuracy at each epoch.\r\n",
        "\r\n",
        "3. Create an EarlyStopping object called early_stopping_monitor. Stop optimization when the validation loss hasn't improved for 2 epochs by specifying the patience parameter of EarlyStopping() to be 2.\r\n",
        "\r\n",
        "4. Fit the model using the predictors and target. Specify the number of epochs to be 30 and use a validation split of 0.3. In addition, pass [early_stopping_monitor] to the callbacks parameter.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HywS_bNtnso8"
      },
      "source": [
        "# Import EarlyStopping\r\n",
        "from keras.callbacks import EarlyStopping\r\n",
        "\r\n",
        "# Save the number of columns in predictors: n_cols\r\n",
        "n_cols = predictors.shape[1]\r\n",
        "input_shape = (n_cols,)\r\n",
        "\r\n",
        "# Specify the model\r\n",
        "model = Sequential()\r\n",
        "model.add(Dense(100, activation='relu', input_shape = input_shape))\r\n",
        "model.add(Dense(100, activation='relu'))\r\n",
        "model.add(Dense(2, activation='softmax'))\r\n",
        "\r\n",
        "# Compile the model\r\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "# Define early_stopping_monitor\r\n",
        "early_stopping_monitor = EarlyStopping(patience=2)\r\n",
        "\r\n",
        "# Fit the model\r\n",
        "model.fit(predictors, target, validation_split = 0.3, epochs = 30, callbacks = [early_stopping_monitor])\r\n",
        "\r\n",
        "'''\r\n",
        "<script.py> output:\r\n",
        "    Train on 623 samples, validate on 268 samples\r\n",
        "    Epoch 1/30\r\n",
        "    \r\n",
        " 32/623 [>.............................] - ETA: 1s - loss: 5.6563 - acc: 0.4688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "416/623 [===================>..........] - ETA: 0s - loss: 1.7946 - acc: 0.5337\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "623/623 [==============================] - 0s - loss: 1.6552 - acc: 0.5730 - val_loss: 1.0194 - val_acc: 0.6791\r\n",
        "    Epoch 2/30\r\n",
        "    \r\n",
        " 32/623 [>.............................] - ETA: 0s - loss: 1.7899 - acc: 0.4688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "416/623 [===================>..........] - ETA: 0s - loss: 0.9214 - acc: 0.5601\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "623/623 [==============================] - 0s - loss: 0.8275 - acc: 0.6051 - val_loss: 0.5729 - val_acc: 0.7313\r\n",
        "    Epoch 3/30\r\n",
        "    \r\n",
        " 32/623 [>.............................] - ETA: 0s - loss: 0.9198 - acc: 0.6250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "288/623 [============>.................] - ETA: 0s - loss: 0.7700 - acc: 0.6076\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "623/623 [==============================] - 0s - loss: 0.7860 - acc: 0.6212 - val_loss: 0.6576 - val_acc: 0.7276\r\n",
        "    Epoch 4/30\r\n",
        "    \r\n",
        " 32/623 [>.............................] - ETA: 0s - loss: 1.3512 - acc: 0.5625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "448/623 [====================>.........] - ETA: 0s - loss: 0.7426 - acc: 0.6071\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "623/623 [==============================] - 0s - loss: 0.7342 - acc: 0.6340 - val_loss: 0.5421 - val_acc: 0.7239\r\n",
        "    Epoch 5/30\r\n",
        "    \r\n",
        " 32/623 [>.............................] - ETA: 0s - loss: 0.5706 - acc: 0.7188\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "512/623 [=======================>......] - ETA: 0s - loss: 0.6592 - acc: 0.6543\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "623/623 [==============================] - 0s - loss: 0.6567 - acc: 0.6581 - val_loss: 0.5783 - val_acc: 0.7127\r\n",
        "    Epoch 6/30\r\n",
        "    \r\n",
        " 32/623 [>.............................] - ETA: 0s - loss: 0.4341 - acc: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "384/623 [=================>............] - ETA: 0s - loss: 0.5997 - acc: 0.7031\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "623/623 [==============================] - 0s - loss: 0.5966 - acc: 0.6902 - val_loss: 0.6056 - val_acc: 0.6903\r\n",
        "    Epoch 7/30\r\n",
        "    \r\n",
        " 32/623 [>.............................] - ETA: 0s - loss: 0.6419 - acc: 0.6875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "448/623 [====================>.........] - ETA: 0s - loss: 0.5984 - acc: 0.7121\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "623/623 [==============================] - 0s - loss: 0.6401 - acc: 0.7063 - val_loss: 0.7635 - val_acc: 0.6493\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbTDKZcEn2T-"
      },
      "source": [
        "Conclusion\r\n",
        "\r\n",
        "Wonderful work! Because optimization will automatically stop when it is no longer helpful, it is okay to specify the maximum number of epochs as 30 rather than using the default of 10 that you've used so far. Here, it seems like the optimization stopped after 7 epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTPEjbiAoH29"
      },
      "source": [
        "# Experimenting with wider networks\r\n",
        "\r\n",
        "Now you know everything you need to begin experimenting with different models!\r\n",
        "\r\n",
        "A model called model_1 has been pre-loaded. You can see a summary of this model printed in the IPython Shell. This is a relatively small network, with only 10 units in each hidden layer.\r\n",
        "\r\n",
        "In this exercise you'll create a new model called model_2 which is similar to model_1, except it has 100 units in each hidden layer.\r\n",
        "\r\n",
        "After you create model_2, both models will be fitted, and a graph showing both models loss score at each epoch will be shown. We added the argument verbose=False in the fitting commands to print out fewer updates, since you will look at these graphically instead of as text.\r\n",
        "\r\n",
        "Because you are fitting two models, it will take a moment to see the outputs after you hit run, so be patient.\r\n",
        "\r\n",
        "Instructions\r\n",
        "\r\n",
        "1. Create model_2 to replicate model_1, but use 100 nodes instead of 10 for the first two Dense layers you add with the 'relu' activation. Use 2 nodes for the Dense output layer with 'softmax' as the activation.\r\n",
        "\r\n",
        "2. Compile model_2 as you have done with previous models: Using 'adam' as the optimizer, 'categorical_crossentropy' for the loss, and metrics=['accuracy'].\r\n",
        "\r\n",
        "3. Hit 'Submit Answer' to fit both the models and visualize which one gives better results! Notice the keyword argument verbose=False in model.fit(): This prints out fewer updates, since you'll be evaluating the models graphically instead of through text.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrgvG1uzoVOR"
      },
      "source": [
        "# Model 1 Summary\r\n",
        "_____________________________________________________________\r\n",
        "Layer (type)                 Output Shape              Param #   \r\n",
        "=================================================================\r\n",
        "dense_1 (Dense)              (None, 10)                110       \r\n",
        "_________________________________________________________________\r\n",
        "dense_2 (Dense)              (None, 10)                110       \r\n",
        "_________________________________________________________________\r\n",
        "dense_3 (Dense)              (None, 2)                 22        \r\n",
        "=================================================================\r\n",
        "Total params: 242.0\r\n",
        "Trainable params: 242\r\n",
        "Non-trainable params: 0.0\r\n",
        "_________________________________________________________________\r\n",
        "None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2Wvl3ISpXTb"
      },
      "source": [
        "# Define early_stopping_monitor\r\n",
        "early_stopping_monitor = EarlyStopping(patience=2)\r\n",
        "\r\n",
        "# Create the new model: model_2\r\n",
        "model_2 = Sequential()\r\n",
        "\r\n",
        "# Add the first and second layers\r\n",
        "model_2.add(Dense(100, activation = 'relu', input_shape=input_shape))\r\n",
        "model_2.add(Dense(100, activation = 'relu', input_shape=input_shape))\r\n",
        "\r\n",
        "# Add the output layer\r\n",
        "model_2.add(Dense(2, activation = 'softmax'))\r\n",
        "\r\n",
        "# Compile model_2\r\n",
        "model_2.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\r\n",
        "\r\n",
        "# Fit model_1\r\n",
        "model_1_training = model_1.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\r\n",
        "\r\n",
        "# Fit model_2\r\n",
        "model_2_training = model_2.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\r\n",
        "\r\n",
        "# Create the plot\r\n",
        "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\r\n",
        "plt.xlabel('Epochs')\r\n",
        "plt.ylabel('Validation score')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeJX2Th3pipH"
      },
      "source": [
        "Conclusion\r\n",
        "\r\n",
        "The blue model is the one you made, the red is the original model. Your model had a lower loss value, so it is the better model. Nice job!\r\n",
        "\r\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whWWsVNcpm6R"
      },
      "source": [
        "# Adding layers to a network\r\n",
        "\r\n",
        "You've seen how to experiment with wider networks. In this exercise, you'll try a deeper network (more hidden layers).\r\n",
        "\r\n",
        "Once again, you have a baseline model called model_1 as a starting point. It has 1 hidden layer, with 50 units. You can see a summary of that model's structure printed out. You will create a similar network with 3 hidden layers (still keeping 50 units in each layer).\r\n",
        "\r\n",
        "This will again take a moment to fit both models, so you'll need to wait a few seconds to see the results after you run your code.\r\n",
        "\r\n",
        "Instructions\r\n",
        "\r\n",
        "1. Specify a model called model_2 that is like model_1, but which has 3 hidden layers of 50 units instead of only 1 hidden layer.\r\n",
        "        \r\n",
        " - Use input_shape to specify the input shape in the first hidden layer.\r\n",
        "\r\n",
        " - Use 'relu' activation for the 3 hidden layers and 'softmax' for the output layer, which should have 2 units.\r\n",
        "    \r\n",
        "2. Compile model_2 as you have done with previous models: Using 'adam' as the optimizer, 'categorical_crossentropy' for the loss, and metrics=['accuracy'].\r\n",
        "    \r\n",
        "3. Hit 'Submit Answer' to fit both the models and visualize which one gives better results! For both models, you should look for the best val_loss and val_acc, which won't be the last epoch for that model.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fw8PKpzqBFb"
      },
      "source": [
        "# Model_1 Summary\r\n",
        "_______________________________________________________\r\n",
        "Layer (type)                 Output Shape              Param #   \r\n",
        "=================================================================\r\n",
        "dense_1 (Dense)              (None, 50)                550       \r\n",
        "_________________________________________________________________\r\n",
        "dense_2 (Dense)              (None, 2)                 102       \r\n",
        "=================================================================\r\n",
        "Total params: 652.0\r\n",
        "Trainable params: 652\r\n",
        "Non-trainable params: 0.0\r\n",
        "_________________________________________________________________\r\n",
        "None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_Bv44_ostbJ"
      },
      "source": [
        "# The input shape to use in the first hidden layer\r\n",
        "input_shape = (n_cols,)\r\n",
        "\r\n",
        "# Create the new model: model_2\r\n",
        "model_2 = Sequential()\r\n",
        "\r\n",
        "# Add the first, second, and third hidden layers\r\n",
        "model_2.add(Dense(50, activation = 'relu', input_shape=input_shape))\r\n",
        "model_2.add(Dense(50, activation = 'relu', input_shape=input_shape))\r\n",
        "model_2.add(Dense(50, activation = 'relu', input_shape=input_shape))\r\n",
        "\r\n",
        "# Add the output layer\r\n",
        "model_2.add(Dense(2, activation = 'softmax'))\r\n",
        "\r\n",
        "# Compile model_2\r\n",
        "model_2.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\r\n",
        "\r\n",
        "# Fit model 1\r\n",
        "model_1_training = model_1.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\r\n",
        "\r\n",
        "# Fit model 2\r\n",
        "model_2_training = model_2.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\r\n",
        "\r\n",
        "# Create the plot\r\n",
        "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\r\n",
        "plt.xlabel('Epochs')\r\n",
        "plt.ylabel('Validation score')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psUCzb_ms5a3"
      },
      "source": [
        "Conclusion\r\n",
        "\r\n",
        "Great work! The blue model is the one you made and the red is the original model. The model with the lower loss value is the better model.\r\n",
        "\r\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssq3J-_fs_g_"
      },
      "source": [
        "# Thinking about model capacity\r\n",
        "\r\n",
        "1. Thinking about model capacity\r\n",
        "\r\n",
        "At this point, you know how to run experiments, and compare different models performance. However, it takes some practice to get an intuition for what experiments or architectures to try. There is still a little more art to finding good deep learning architectures than there is for tuning other machine learning algorithms. But something called \"model capacity\" should be one of the key considerations you think about when deciding what models to try.\"Model capacity\" or \"network capacity\" is closely related to the terms overfitting and underfitting.\r\n",
        "2. Overfitting\r\n",
        "\r\n",
        "You may recall overfitting and a graphic like this from a previous DataCamp course. Overfitting is the ability of a model to fit oddities in your training data that are there purely due to happenstance, and that won't apply in a new dataset. When you are overfitting, your model will make accurate predictions on training data, but it will make inaccurate predictions on validation data and new datasets. Underfitting is the opposite. That is when your model fails to find important predictive patterns in the training data. So it is accurate in neither the training data nor validation data. Because we want to do well on new datasets that weren't used for training the model, our validation score is the ultimate measure of a model's predictive quality. Let's get back to model capacity. Model capacity is a model's ability to capture predictive patterns in your data. So, the more capacity a model, the further to the right we will be on this graph. If you had a network, and you increased the number of nodes or neurons in a hidden layer, that would increase model capacity. And if you add layers, that increases capacity. Said another way, making larger layers or increasing the number of layers moves you further to the right of this graph. So, with that in mind,\r\n",
        "3. Workflow for optimizing model capacity\r\n",
        "\r\n",
        "here is a good workflow for you. Start with a simple network, and get the validation score. Then keep adding capacity as long as the score keeps improving. Once it stops improving, you can decrease capacity slightly, but you are probably near the ideal.\r\n",
        "4. Sequential experiments\r\n",
        "\r\n",
        "Let's walk through that process once. Here, I've started a model that has one hidden layer and 100 units. That's a relatively simple, or low capacity, model. I get a mean squared error\r\n",
        "5. Sequential experiments\r\n",
        "\r\n",
        "of 5-point-4. Since I started with a simple model, I now try increasing capacity. I could increase the number of layers or use more hidden nodes. I'll start by using more nodes in the one hidden layer. That improved the model, so I'll keep increasing capacity.\r\n",
        "6. Sequential experiments\r\n",
        "\r\n",
        "This time I'll switch to using 2 hidden layers. Each layer has 250 nodes. That improved the error more. So, I try 3 layers, continuing to add capacity as long as it helps.\r\n",
        "7. Sequential experiments\r\n",
        "\r\n",
        "This hurt the score. So, the model with 2 layers and 250 nodes is about perfect. I'll try another model that reduces capacity slightly from the last model I built.\r\n",
        "8. Sequential experiments\r\n",
        "\r\n",
        "That is 3 hidden layers with 200 nodes each. That seems the best model yet. So I'll stick with that. Should you change capacity by adding layers or by adding nodes to an existing layer? There isn't a universal answer to that. You can experiment. But you should generally be thinking about whether you are trying to increase or decrease capacity, ideally honing in on the right capacity by looking at validation scores. -\r\n",
        "9. Let's practice!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upbk3U2a2vEO"
      },
      "source": [
        "# Experimenting with model structures\r\n",
        "\r\n",
        "You've just run an experiment where you compared two networks that were identical except that the 2nd network had an extra hidden layer. You see that this 2nd network (the deeper network) had better performance. Given that, which of the following would be a good experiment to run next for even better performance?\r\n",
        "\r\n",
        "Possible Answers\r\n",
        "\r\n",
        "1. Try a new network with fewer layers than anything you have tried yet.\r\n",
        " - Incorrect - reducing the number of layers is unlikely to improve performance.\r\n",
        "\r\n",
        "2. Use more units in each hidden layer.\r\n",
        " - Incorrect - Well done! Increasing the number of units in each hidden layer would be a good next step to try achieving even better performance.\r\n",
        "\r\n",
        "3. Use fewer units in each hidden layer.\r\n",
        " - Incorrect - Not quite - using fewer units in each hidden layer is unlikely to improve performance.'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zjF5qtA3W5S"
      },
      "source": [
        "# Stepping up to images\r\n",
        "\r\n",
        "1. Stepping up to images\r\n",
        "\r\n",
        "To close, you are going to apply your knowledge to a new and different dataset.\r\n",
        "2. Recognizing handwritten digits\r\n",
        "\r\n",
        "This is the MNIST dataset, which contains images of handwritten digits. This is a very popular dataset for getting started working with images. There is an image of each handwritten digit, and each image is composed of a 28 pixel by 28 pixel grid. The image is represented by showing how dark each pixel is. So, 0 would be as light as possible, and 255 is as dark as possible. I've flattened the 28 x 28 grid for you into a 784 x 1 array for each image. Each image shows a digit like 0, 1, 2, 3 4, all the way up to 9. Your model will predict which digit it is that was written. So you will create a deep learning model taking in those 784 features for each image as inputs, and predicting digits from among 10 possible values for the output. -\r\n",
        "3. Let's practice!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Klto5BLb4p9c"
      },
      "source": [
        "# Building your own digit recognition model\r\n",
        "\r\n",
        "You've reached the final exercise of the course - you now know everything you need to build an accurate model to recognize handwritten digits!\r\n",
        "\r\n",
        "We've already done the basic manipulation of the MNIST dataset shown in the video, so you have X and y loaded and ready to model with. Sequential and Dense from keras are also pre-imported.\r\n",
        "\r\n",
        "To add an extra challenge, we've loaded only 2500 images, rather than 60000 which you will see in some published results. Deep learning models perform better with more data, however, they also take longer to train, especially when they start becoming more complex.\r\n",
        "\r\n",
        "If you have a computer with a CUDA compatible GPU, you can take advantage of it to improve computation time. If you don't have a GPU, no problem! You can set up a deep learning environment in the cloud that can run your models on a GPU. Here is a [blog post](https://www.datacamp.com/community/tutorials/deep-learning-jupyter-aws) by Dan that explains how to do this - check it out after completing this exercise! It is a great next step as you continue your deep learning journey.\r\n",
        "\r\n",
        "Ready to take your deep learning to the next level? Check out [Advanced Deep Learning with Keras](https://www.datacamp.com/courses/advanced-deep-learning-with-keras-in-python) in Python to see how the Keras functional API lets you build domain knowledge to solve new types of problems. Once you know how to use the functional API, take a look at [\"Convolutional Neural Networks for Image Processing\"](https://www.datacamp.com/courses/convolutional-neural-networks-for-image-processing) to learn image-specific applications of Keras.\r\n",
        "\r\n",
        "Instructions\r\n",
        "\r\n",
        "1. Create a Sequential object to start your model. Call this model.\r\n",
        "\r\n",
        "2. Add the first Dense hidden layer of 50 units to your model with 'relu' activation. For this data, the input_shape is (784,).\r\n",
        "\r\n",
        "3. Add a second Dense hidden layer with 50 units and a 'relu' activation function.\r\n",
        "\r\n",
        "4. Add the output layer. Your activation function should be 'softmax', and the number of nodes in this layer should be the same as the number of possible outputs in this case: 10.\r\n",
        "\r\n",
        "5. Compile model as you have done with previous models: Using 'adam' as the optimizer, 'categorical_crossentropy' for the loss, and metrics=['accuracy'].\r\n",
        "\r\n",
        "6. Fit the model using X and y using a validation_split of 0.3.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyLoJB8b6b0H"
      },
      "source": [
        "# Create the model: model\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "# Add the first hidden layer\r\n",
        "model.add(Dense(50, activation = 'relu', input_shape=(784,)))\r\n",
        "\r\n",
        "# Add the second hidden layer\r\n",
        "model.add(Dense(50, activation = 'relu', input_shape=(784,)))\r\n",
        "\r\n",
        "# Add the output layer\r\n",
        "model.add(Dense(10, activation = 'softmax'))\r\n",
        "\r\n",
        "# Compile the model\r\n",
        "model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "# Fit the model\r\n",
        "model.fit(X, y, validation_split = 0.3)\r\n",
        "\r\n",
        "'''\r\n",
        "<script.py> output:\r\n",
        "    Train on 1750 samples, validate on 750 samples\r\n",
        "    Epoch 1/10\r\n",
        "    \r\n",
        "  32/1750 [..............................] - ETA: 2s - loss: 2.1979 - acc: 0.2188\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        " 544/1750 [========>.....................] - ETA: 0s - loss: 2.1415 - acc: 0.2518\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "1056/1750 [=================>............] - ETA: 0s - loss: 1.9387 - acc: 0.3456\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "1600/1750 [==========================>...] - ETA: 0s - loss: 1.7294 - acc: 0.4375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "1750/1750 [==============================] - 0s - loss: 1.6717 - acc: 0.4663 - val_loss: 1.0087 - val_acc: 0.7720\r\n",
        "    Epoch 2/10\r\n",
        "    \r\n",
        "  32/1750 [..............................] - ETA: 0s - loss: 0.9445 - acc: 0.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        " 576/1750 [========>.....................] - ETA: 0s - loss: 0.7594 - acc: 0.8385\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "1120/1750 [==================>...........] - ETA: 0s - loss: 0.7221 - acc: 0.8313\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "1664/1750 [===========================>..] - ETA: 0s - loss: 0.6792 - acc: 0.8311\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "1750/1750 [==============================] - 0s - loss: 0.6765 - acc: 0.8297 - val_loss: 0.5309 - val_acc: 0.8640\r\n",
        "    Epoch 3/10\r\n",
        "    \r\n",
        "  32/1750 [..............................] - ETA: 0s - loss: 0.3715 - acc: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        " 512/1750 [=======>......................] - ETA: 0s - loss: 0.4189 - acc: 0.8965\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        " 928/1750 [==============>...............] - ETA: 0s - loss: 0.4044 - acc: 0.8987\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "1312/1750 [=====================>........] - ETA: 0s - loss: 0.3986 - acc: 0.8986\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "1664/1750 [===========================>..] - ETA: 0s - loss: 0.4164 - acc: 0.8882\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "1750/1750 [==============================] - 0s - loss: 0.4164 - acc: 0.8869 - val_loss: 0.4478 - val_acc: 0.8667\r\n",
        "    Epoch 4/10\r\n",
        "    \r\n",
        "  32/1750 [..............................] - ETA: 0s - loss: 0.1797 - acc: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        " 544/1750 [========>.....................] - ETA: 0s - loss: 0.2932 - acc: 0.9320\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "1088/1750 [=================>............] - ETA: 0s - loss: 0.3258 - acc: 0.9136\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "1632/1750 [==========================>...] - ETA: 0s - loss: 0.3286 - acc: 0.9087\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "1750/1750 [==============================] - 0s - loss: 0.3222 - acc: 0.9103 - val_loss: 0.3898 - val_acc: 0.8800\r\n",
        "    Epoch 5/10\r\n",
        "    \r\n",
        "  32/1750 [..............................] - ETA: 0s - loss: 0.1696 - acc: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        " 352/1750 [=====>........................] - ETA: 0s - loss: 0.2529 - acc: 0.9347\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        " 704/1750 [===========>..................] - ETA: 0s - loss: 0.2738 - acc: 0.9233\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "1088/1750 [=================>............] - ETA: 0s - loss: 0.2513 - acc: 0.9320\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "1504/1750 [========================>.....] - ETA: 0s - loss: 0.2476 - acc: 0.9302\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "1750/1750 [==============================] - 0s - loss: 0.2588 - acc: 0.9280 - val_loss: 0.3684 - val_acc: 0.8947\r\n",
        "    Epoch 6/10\r\n",
        "    \r\n",
        "  32/1750 [..............................] - ETA: 0s - loss: 0.0787 - acc: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        " 576/1750 [========>.....................] - ETA: 0s - loss: 0.1956 - acc: 0.9531\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "1120/1750 [==================>...........] - ETA: 0s - loss: 0.1988 - acc: 0.9527\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "1600/1750 [==========================>...] - ETA: 0s - loss: 0.2033 - acc: 0.9481\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "1750/1750 [==============================] - 0s - loss: 0.2079 - acc: 0.9457 - val_loss: 0.3472 - val_acc: 0.8933\r\n",
        "    Epoch 7/10\r\n",
        "    \r\n",
        "  32/1750 [..............................] - ETA: 0s - loss: 0.1727 - acc: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        " 448/1750 [======>.......................] - ETA: 0s - loss: 0.1584 - acc: 0.9665\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        " 960/1750 [===============>..............] - ETA: 0s - loss: 0.1633 - acc: 0.9625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "1504/1750 [========================>.....] - ETA: 0s - loss: 0.1727 - acc: 0.9574\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "1750/1750 [==============================] - 0s - loss: 0.1708 - acc: 0.9577 - val_loss: 0.3291 - val_acc: 0.8947\r\n",
        "    Epoch 8/10\r\n",
        "    \r\n",
        "  32/1750 [..............................] - ETA: 0s - loss: 0.0899 - acc: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        " 448/1750 [======>.......................] - ETA: 0s - loss: 0.1647 - acc: 0.9643\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        " 864/1750 [=============>................] - ETA: 0s - loss: 0.1436 - acc: 0.9711\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "1344/1750 [======================>.......] - ETA: 0s - loss: 0.1391 - acc: 0.9695\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "1750/1750 [==============================] - 0s - loss: 0.1406 - acc: 0.9691 - val_loss: 0.3218 - val_acc: 0.9040\r\n",
        "    Epoch 9/10\r\n",
        "    \r\n",
        "  32/1750 [..............................] - ETA: 0s - loss: 0.0529 - acc: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        " 512/1750 [=======>......................] - ETA: 0s - loss: 0.0854 - acc: 0.9902\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        " 928/1750 [==============>...............] - ETA: 0s - loss: 0.1023 - acc: 0.9860\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "1408/1750 [=======================>......] - ETA: 0s - loss: 0.1074 - acc: 0.9837\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "1750/1750 [==============================] - 0s - loss: 0.1140 - acc: 0.9806 - val_loss: 0.3395 - val_acc: 0.8947\r\n",
        "    Epoch 10/10\r\n",
        "    \r\n",
        "  32/1750 [..............................] - ETA: 0s - loss: 0.1628 - acc: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        " 576/1750 [========>.....................] - ETA: 0s - loss: 0.1181 - acc: 0.9740\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "1088/1750 [=================>............] - ETA: 0s - loss: 0.1004 - acc: 0.9816\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "1536/1750 [=========================>....] - ETA: 0s - loss: 0.0995 - acc: 0.9805\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
        "1750/1750 [==============================] - 0s - loss: 0.0980 - acc: 0.9811 - val_loss: 0.3139 - val_acc: 0.9013\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmKwVfaI7NjU"
      },
      "source": [
        "Conclusion\r\n",
        "\r\n",
        "Congrats! You've done something pretty amazing. You should see better than 90% accuracy recognizing handwritten digits, even while using a small training set of only 1750 images!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7jOmMtn7SG2"
      },
      "source": [
        "# Final thoughts\r\n",
        "\r\n",
        "1. Final thoughts\r\n",
        "\r\n",
        "Congrats. You are on your way to using the most fun and powerful modeling technique around.\r\n",
        "2. Next steps\r\n",
        "\r\n",
        "There is still an immense amount to learn as you become a deep learning master. But it's like riding a bike. The hardest part is getting to the point where you can practice on your own, and you are there. You'll probably enjoy experimenting with deep learning using the same types of data you've used before for predictive modeling, tables of numeric data like what you commonly see in a pandas DataFrame or numpy array. From there, many people start working with images, using something called convolutional neural networks. But you could decide you want to focus on text. Or sound. Or you might get creative and apply deep learning to data others haven't even thought of. You'll find it's a powerful technique as you get the hang of it. Kaggle is a great place to find datasets to work with, and their forums are a great place to keep learning. As you get more advanced, start checking out the wikipedia page titled \"List of datasets for machine learning research.\" It includes datasets from some very interesting domains. Keras has excellent documentation. When there's something specific to look up, keras-dot-io is likely to have the answer. The keras and tensorflow repositories on github also have nice examples to work from. As you start working with larger datasets and more complex deep learning models, you may find these models can take a long time to fit. If you have a computer with a graphical processing unit, or GPU, you may be able to set up TensorFlow to use that GPU for computation. This generally requires a GPU that meets a standard called CUDA compatibility. Most GPU's made by NVIDIA are CUDA compatible. If you don't have a computer with a CUDA compatible GPU, here is a link with instructions about setting up a deep learning environment in the cloud that can run your models on a GPU. More than anything, share your work online, and have fun. If you keep experimenting and build out on the tools you've learned, you'll soon be amazed at what you can do.\r\n",
        "3. Let's practice!"
      ]
    }
  ]
}