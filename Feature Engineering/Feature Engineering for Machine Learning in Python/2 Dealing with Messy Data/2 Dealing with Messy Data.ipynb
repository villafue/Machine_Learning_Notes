{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2 Dealing with Messy Data.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPCQDDL+4Bu/OsoxrmC2yal",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/villafue/Machine_Learning_Notes/blob/master/Feature%20Engineering/Feature%20Engineering%20for%20Machine%20Learning%20in%20Python/2%20Dealing%20with%20Messy%20Data/2%20Dealing%20with%20Messy%20Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rbrxZR5FtVv"
      },
      "source": [
        "# Dealing with Messy Data\r\n",
        "\r\n",
        "This chapter introduces you to the reality of messy and incomplete data. You will learn how to find where your data has missing values and explore multiple approaches on how to deal with them. You will also use string manipulation techniques to deal with unwanted characters in your dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyx7BHVeFvRb"
      },
      "source": [
        "# 1. Why do missing values exist?\r\n",
        "\r\n",
        "In the first chapter, we looked at the different types of data one may find when analyzing data. In this lesson, we will explore the concept of messy and missing values, how to find them, and once identified, how to deal with them.\r\n",
        "\r\n",
        "2. How gaps in data occur\r\n",
        "While in an ideal world every data set you come across would be perfectly complete and contain no gaps, unfortunately, this is rarely the case. Real world data often has noise or omissions. This can stem from many sources, for example: Data not being collected properly (paper surveys not being filled out fully). Collection and management errors (someone transcribing the data making a mistake). Data intentionally being omitted (people may want to skip the age box in an online form). Or gaps could be created due to transformations of the data (average of a field with missing data). This list is far from comprehensive.\r\n",
        "\r\n",
        "3. Why we care?\r\n",
        "You may wonder why are we discussing this? Does missing data even matter? Yes, it does, and it is extremely important to identify and deal with missing data. Many machine learning models cannot work with missing values, for example if you were performing linear regression, you would need a value for every row and column used in your data set. Missing data may be indicative of a problem in your data pipeline. If data is consistently missing in a certain column, you should investigate as to why this is the case. Missing data may provide information in itself. For example, if the number of children of a person is missing they may have no children.\r\n",
        "\r\n",
        "4. Missing value discovery\r\n",
        "You can use the info() method to have a preliminary look at how complete the data set is. Right from the get go you can see that the StackOverflowJobsRecommend, Gender, and RawSalary columns are highly underpopulated and we should examine where these missing values occur. This list output is useful but becomes limited with larger datasets that have missing values scattered all over their features.\r\n",
        "\r\n",
        "5. Finding missing values\r\n",
        "To find where these missing values exist, you can use the isnull() method as shown here. All cells where missing values exist are shown as True.\r\n",
        "\r\n",
        "6. Finding missing values\r\n",
        "You can also count the number of missing values in a specific column by chaining the isnull() and sum() methods as shown here.\r\n",
        "\r\n",
        "7. Finding non-missing values\r\n",
        "The inverse (or the non missing values) can also be found using the notnull() method. Here, all missing values are shown as False. Note that you can call the isnull() and notnull() methods on both the DataFrame as a whole, and on each of it's individual columns.\r\n",
        "\r\n",
        "8. Go ahead and find missing values!\r\n",
        "It's time for you to find missing values in the Stackoverflow data!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VR13GTdFyGp"
      },
      "source": [
        "# How sparse is my data?\r\n",
        "\r\n",
        "Most data sets contain missing values, often represented as NaN (Not a Number). If you are working with Pandas you can easily check how many missing values exist in each column.\r\n",
        "\r\n",
        "Let's find out how many of the developers taking the survey chose to enter their age (found in the Age column of so_survey_df) and their gender (Gender column of so_survey_df).\r\n",
        "\r\n",
        "Instructions\r\n",
        "\r\n",
        "1. Subset the DataFrame to only include the 'Age' and 'Gender' columns.\r\n",
        "\r\n",
        "2. Print the number of non-missing values in both columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AknxYUwxFq4n"
      },
      "source": [
        "# Subset the DataFrame\r\n",
        "sub_df = so_survey_df[['Age', 'Gender']]\r\n",
        "\r\n",
        "# Print the number of non-missing values\r\n",
        "print(sub_df.notnull().sum())\r\n",
        "\r\n",
        "'''\r\n",
        "Age       999\r\n",
        "Gender    693\r\n",
        "dtype: int64\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDoWx_IYUh-S"
      },
      "source": [
        "Question\r\n",
        "\r\n",
        "3. Based on the results, how many non-missing entries are there in the Gender column?\r\n",
        "\r\n",
        "Possible Answers\r\n",
        "\r\n",
        "- 999\r\n",
        "\r\n",
        "- 693\r\n",
        " - Correct, there are 693 non-missing entries in the Gender column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjIOstm4UxbG"
      },
      "source": [
        "# Finding the missing values\r\n",
        "\r\n",
        "While having a summary of how much of your data is missing can be useful, often you will need to find the exact locations of these missing values. Using the same subset of the StackOverflow data from the last exercise (sub_df), you will show how a value can be flagged as missing.\r\n",
        "\r\n",
        "Instructions\r\n",
        "\r\n",
        "1. Print the first 10 entries of the DataFrame.\r\n",
        "\r\n",
        "2. Print the locations of the missing values in the first 10 rows.\r\n",
        "\r\n",
        "3. Print the locations of the non-missing values in the first 10 rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EmZbU1xFs8j"
      },
      "source": [
        "# Print the top 10 entries of the DataFrame\r\n",
        "print(sub_df.head(10))\r\n",
        "\r\n",
        "'''\r\n",
        " Age  Gender\r\n",
        "0   21    Male\r\n",
        "1   38    Male\r\n",
        "2   45     NaN\r\n",
        "3   46    Male\r\n",
        "4   39    Male\r\n",
        "5   39    Male\r\n",
        "6   34    Male\r\n",
        "7   24  Female\r\n",
        "8   23    Male\r\n",
        "9   36     NaN\r\n",
        "'''\r\n",
        "\r\n",
        "# Print the locations of the missing values\r\n",
        "print(sub_df.head(10).isnull())\r\n",
        "\r\n",
        "'''\r\n",
        "Age  Gender\r\n",
        "0  False   False\r\n",
        "1  False   False\r\n",
        "2  False    True\r\n",
        "3  False   False\r\n",
        "4  False   False\r\n",
        "5  False   False\r\n",
        "6  False   False\r\n",
        "7  False   False\r\n",
        "8  False   False\r\n",
        "9  False    True\r\n",
        "'''\r\n",
        "\r\n",
        "# Print the locations of the non-missing values\r\n",
        "print(sub_df.head(10).notnull())\r\n",
        "\r\n",
        "'''\r\n",
        "<script.py> output:\r\n",
        "        Age  Gender\r\n",
        "    0  True    True\r\n",
        "    1  True    True\r\n",
        "    2  True   False\r\n",
        "    3  True    True\r\n",
        "    4  True    True\r\n",
        "    5  True    True\r\n",
        "    6  True    True\r\n",
        "    7  True    True\r\n",
        "    8  True    True\r\n",
        "    9  True   False\r\n",
        "'''\r\n",
        "'''\r\n",
        "Conclusion: Well done, finding where the missing values exist can often be important.\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRfnWl7XVqHy"
      },
      "source": [
        "# Dealing with missing values (I)\r\n",
        "\r\n",
        "1. Dealing with missing values (I)\r\n",
        "Now that you can recognize why missing values occur and how to locate them, you need to know how they can be dealt with.\r\n",
        "\r\n",
        "2. Listwise deletion\r\n",
        "If you are confident that the missing values in your data set are occurring at random, (in other words not being intentionally omitted) the most effective and statistically sound approach to dealing with them is called 'complete case analysis' or listwise deletion. In this method, a record is fully excluded from your model if any of its values are missing. Take for example the dataset shown here. Although most of the information is available in the first and third rows, because values in the ConvertedSalary column are missing, these rows will be dropped.\r\n",
        "\r\n",
        "3. Listwise deletion in Python\r\n",
        "To implement listwise deletion using pandas, you can use the dropna() method, by setting the how argument to 'any'. This will delete all rows with at least one missing value.\r\n",
        "\r\n",
        "4. Listwise deletion in Python\r\n",
        "On the other hand, if you want to delete rows with missing values in only a specific column, you can use the subset argument. Pass a list of columns to this argument to specify which columns to consider when deleting rows.\r\n",
        "\r\n",
        "5. Issues with deletion\r\n",
        "While the preferable approach in situations where missing data occurs purely at random is listwise deletion, it does have its drawbacks. First, it deletes perfectly valid data points that share a row with a missing value. Second, if the missing values do not occur entirely at random it can negatively affect the model. Lastly, if you were to remove a feature instead of a row it can reduce the degrees of freedom of your model.\r\n",
        "\r\n",
        "6. Replacing with strings\r\n",
        "The most common way to deal with missing values is to simply fill these values using the fillna() method. To use the fillna() method on a specific column, you need to provide the value you want to replace the missing values with. In the case of categorical columns, it is common to replace missing values with strings like 'Other', 'Not Given' etc. To replace the missing values in place, in other words to modify the original DataFrame, you need to set the inplace argument to True.\r\n",
        "\r\n",
        "7. Recording missing values\r\n",
        "In situations where you believe that the absence or presence of data is more important than the values themselves, you can create a new column that records the absence of data and then drop the original column. To do this, all you need to do is call the notnull() method on a specific column. This will output a list of True/False values, thus recording the presence/absence of data. To drop columns from a DataFrame, you can use the drop() method and specify a list of column names which you want to drop as the columns argument.\r\n",
        "\r\n",
        "8. Practice time\r\n",
        "With this in mind you will now work through applying listwise deletion, and some alternatives for replacing missing values in categorical columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6RxcChlXbJE"
      },
      "source": [
        "# Listwise deletion\r\n",
        "\r\n",
        "The simplest way to deal with missing values in your dataset when they are occurring entirely at random is to remove those rows, also called 'listwise deletion'.\r\n",
        "\r\n",
        "Depending on the use case, you will sometimes want to remove all missing values in your data while other times you may want to only remove a particular column if too many values are missing in that column.\r\n",
        "\r\n",
        "Instructions\r\n",
        "\r\n",
        "1. Print the number of rows and columns in so_survey_df.\r\n",
        "\r\n",
        "2. Drop all rows with missing values in so_survey_df.\r\n",
        "\r\n",
        "3. Drop all columns with missing values in so_survey_df.\r\n",
        "\r\n",
        "4. Drop all rows in so_survey_df where 'Gender' is missing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sS4-G4DXt4l"
      },
      "source": [
        "# Print the number of rows and columns\r\n",
        "print(so_survey_df.shape)\r\n",
        "'''\r\n",
        "(999, 11)\r\n",
        "'''\r\n",
        "\r\n",
        "# Create a new DataFrame dropping all incomplete rows\r\n",
        "no_missing_values_rows = so_survey_df.dropna(how='any')\r\n",
        "\r\n",
        "# Print the shape of the new DataFrame\r\n",
        "print(no_missing_values_rows.shape)\r\n",
        "'''\r\n",
        "(264, 11)\r\n",
        "'''\r\n",
        "\r\n",
        "# Create a new DataFrame dropping all columns with incomplete rows\r\n",
        "no_missing_values_cols = so_survey_df.dropna(how='any', axis=1)\r\n",
        "\r\n",
        "# Print the shape of the new DataFrame\r\n",
        "print(no_missing_values_cols.shape)\r\n",
        "'''\r\n",
        "(999, 7)\r\n",
        "'''\r\n",
        "\r\n",
        "# Drop all rows where Gender is missing\r\n",
        "no_gender = so_survey_df.dropna(subset=['Gender'])\r\n",
        "\r\n",
        "# Print the shape of the new DataFrame\r\n",
        "print(no_gender.shape)\r\n",
        "'''\r\n",
        "<script.py> output:\r\n",
        "    (693, 11)\r\n",
        "'''\r\n",
        "'''\r\n",
        "Conclusion\r\n",
        "\r\n",
        "Correct, as you can see dropping all rows that contain any missing values may greatly\r\n",
        " reduce the size of your dataset. So you need to think carefully and consider several\r\n",
        " trade-offs when deleting missing values.\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBtUti8vZOrS"
      },
      "source": [
        "# Replacing missing values with constants\r\n",
        "\r\n",
        "While removing missing data entirely maybe a correct approach in many situations, this may result in a lot of information being omitted from your models.\r\n",
        "\r\n",
        "You may find categorical columns where the missing value is a valid piece of information in itself, such as someone refusing to answer a question in a survey. In these cases, you can fill all missing values with a new category entirely, for example 'No response given'.\r\n",
        "\r\n",
        "Instructions\r\n",
        "\r\n",
        "1. Print the count of occurrences of each category in so_survey_df's Gender column.\r\n",
        "\r\n",
        "2. Replace all missing values in the Gender column with the string 'Not Given'. Make changes to the original DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVzM0n2dZfN3"
      },
      "source": [
        "# Print the count of occurrences\r\n",
        "print(so_survey_df['Gender'].value_counts())\r\n",
        "'''\r\n",
        "Male                                                                         632\r\n",
        "Female                                                                        53\r\n",
        "Female;Male                                                                    2\r\n",
        "Transgender                                                                    2\r\n",
        "Male;Non-binary. genderqueer. or gender non-conforming                         1\r\n",
        "Female;Male;Transgender;Non-binary. genderqueer. or gender non-conforming      1\r\n",
        "Female;Transgender                                                             1\r\n",
        "Non-binary. genderqueer. or gender non-conforming                              1\r\n",
        "Name: Gender, dtype: int64\r\n",
        "'''\r\n",
        "\r\n",
        "# Replace missing values\r\n",
        "so_survey_df['Gender'].fillna(value='Not Given', inplace=True)\r\n",
        "\r\n",
        "# Print the count of each value\r\n",
        "print(so_survey_df['Gender'].value_counts())\r\n",
        "'''\r\n",
        "<script.py> output:\r\n",
        "    Male                                                                         632\r\n",
        "    Not Given                                                                    306\r\n",
        "    Female                                                                        53\r\n",
        "    Female;Male                                                                    2\r\n",
        "    Transgender                                                                    2\r\n",
        "    Male;Non-binary. genderqueer. or gender non-conforming                         1\r\n",
        "    Female;Male;Transgender;Non-binary. genderqueer. or gender non-conforming      1\r\n",
        "    Female;Transgender                                                             1\r\n",
        "    Non-binary. genderqueer. or gender non-conforming                              1\r\n",
        "    Name: Gender, dtype: int64\r\n",
        "'''\r\n",
        "'''\r\n",
        "Conclusion \r\n",
        "\r\n",
        "Wonderful! By filling in these missing values you can use the columns in your analyses.\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx9z1OK3aKnF"
      },
      "source": [
        "# Dealing with missing values (II)\r\n",
        "\r\n",
        "1. Fill continuous missing values\r\n",
        "While listwise deletion is often the most statistically sound method of dealing with missing values in cases where you believe the gaps are at random, this will often not be feasible in real world use cases.\r\n",
        "\r\n",
        "2. Deleting missing values\r\n",
        "One of the most common issues with removing all rows with missing values is if you were building a predictive model. If you were to remove all cases that had missing values when training your model, you would quickly run into problems when you received missing values in your test set, where you do not have the option of just not predicting these rows.\r\n",
        "\r\n",
        "3. What else can you do?\r\n",
        "So what's the alternative? Replacing missing values. For categorical columns, as you saw in the last lesson you can either replace missing values with a string that flags missing values such as 'None', or you can use the most common occurring value. However, for numeric columns, you may want to replace missing values with a more suitable value. So what is a suitable value?\r\n",
        "\r\n",
        "4. Measures of central tendency\r\n",
        "In cases like this we often turn to the measures of central tendency, which are the central or typical value for a distribution. The most commonly used values are the mean and the median. One caveat that you must keep in mind when using these methods is that it can lead to biased estimates of the variances and covariances of the features. Similarly, the standard error and test statistics can be incorrectly estimated so if these metrics are needed they should be calculated before the missing values have been filled.\r\n",
        "\r\n",
        "5. Calculating the measures of central tendency\r\n",
        "You can calculate these measures directly from a pandas series by simply calling the required method on the series as shown here. Note that the missing values are excluded by default when calculating these statistics.\r\n",
        "\r\n",
        "6. Fill the missing values\r\n",
        "Then leveraging what you implemented in previous lesson, you can directly fill all missing values using the fillna() method. Only this time you are filling missing values in the ConvertedSalary column with the mean of this column. Since you filled in the missing values with the mean, you may end up with too many decimal places. You can get rid of all the decimal values by changing the data type to integer using the astype() method like so.\r\n",
        "\r\n",
        "7. Rounding values\r\n",
        "or you can first round the mean before filling in the missing values as shown here.\r\n",
        "\r\n",
        "8. Let's Practice!\r\n",
        "Now its your turn to put what you have learned into practice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA-VdVAwfjzB"
      },
      "source": [
        "# Filling continuous missing values\r\n",
        "\r\n",
        "In the last lesson, you dealt with different methods of removing data missing values and filling in missing values with a fixed string. These approaches are valid in many cases, particularly when dealing with categorical columns but have limited use when working with continuous values. In these cases, it may be most valid to fill the missing values in the column with a value calculated from the entries present in the column.\r\n",
        "\r\n",
        "Instructions\r\n",
        "\r\n",
        "1. Print the first five rows of the StackOverflowJobsRecommend column of so_survey_df.\r\n",
        "\r\n",
        "2. Replace the missing values in the StackOverflowJobsRecommend column with its mean. Make changes directly to the original DataFrame.\r\n",
        "\r\n",
        "3. Round the decimal values that you introduced in the StackOverflowJobsRecommend column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnXgg4o8g7d4"
      },
      "source": [
        "# Print the first five rows of StackOverflowJobsRecommend column\r\n",
        "print(so_survey_df.StackOverflowJobsRecommend.head())\r\n",
        "'''\r\n",
        "0    NaN\r\n",
        "1    7.0\r\n",
        "2    8.0\r\n",
        "3    NaN\r\n",
        "4    8.0\r\n",
        "Name: StackOverflowJobsRecommend, dtype: float64\r\n",
        "'''\r\n",
        "\r\n",
        "# Fill missing values with the mean\r\n",
        "so_survey_df['StackOverflowJobsRecommend'].fillna(so_survey_df['StackOverflowJobsRecommend'].mean(), inplace=True)\r\n",
        "\r\n",
        "# Print the first five rows of StackOverflowJobsRecommend column\r\n",
        "print(so_survey_df['StackOverflowJobsRecommend'].head())\r\n",
        "'''\r\n",
        "0    7.061602\r\n",
        "1    7.000000\r\n",
        "2    8.000000\r\n",
        "3    7.061602\r\n",
        "4    8.000000\r\n",
        "Name: StackOverflowJobsRecommend, dtype: float64\r\n",
        "'''\r\n",
        "\r\n",
        "# Fill missing values with the mean\r\n",
        "so_survey_df['StackOverflowJobsRecommend'].fillna(so_survey_df['StackOverflowJobsRecommend'].mean(), inplace=True)\r\n",
        "\r\n",
        "# Round the StackOverflowJobsRecommend values\r\n",
        "so_survey_df['StackOverflowJobsRecommend'] = round(so_survey_df['StackOverflowJobsRecommend'])\r\n",
        "\r\n",
        "# Print the top 5 rows\r\n",
        "print(so_survey_df['StackOverflowJobsRecommend'].head())\r\n",
        "'''\r\n",
        "<script.py> output:\r\n",
        "    0    7.0\r\n",
        "    1    7.0\r\n",
        "    2    8.0\r\n",
        "    3    7.0\r\n",
        "    4    8.0\r\n",
        "    Name: StackOverflowJobsRecommend, dtype: float64\r\n",
        "'''\r\n",
        "'''\r\n",
        "Conclusion\r\n",
        "\r\n",
        "Nicely done, remember you should only round your values if you are certain it is applicable.\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJC3k3FLor4D"
      },
      "source": [
        "# Imputing values in predictive models\r\n",
        "\r\n",
        "When working with predictive models you will often have a separate train and test DataFrames. In these cases you want to ensure no information from your test set leaks into your train set. When filling missing values in data to be used in these situations how should approach the two data sets?\r\n",
        "\r\n",
        "Possible Answers\r\n",
        "\r\n",
        "1. Only fill the train set.\r\n",
        " - Incorrect, gaps in both DataFrames will need to be filled.\r\n",
        "\r\n",
        "2. Only fill the test set.\r\n",
        " - Incorrect, gaps in both DataFrames will need to be filled.\r\n",
        "\r\n",
        "3. Apply the measures of central tendency (mean/median etc.) calculated on the train set to both the train and test sets.\r\n",
        " - Correct, values calculated on the train test should be applied to both DataFrames.\r\n",
        "\r\n",
        "4. Apply the measures of central tendency (mean/median etc.) calculated on the test set to both the train and test sets.\r\n",
        " - Incorrect, you should never calculate values based on your test set.\r\n",
        "\r\n",
        "5. Apply the measures of central tendency (mean/median etc.) calculated on the train set to the train set, and the measures calculated on the test set, to the test set.\r\n",
        " - Incorrect, you should never calculate values based on your test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoFnvszoqW1T"
      },
      "source": [
        "# Dealing with other data issues\r\n",
        "\r\n",
        "1. Dealing with other data issues\r\n",
        "Up to this point you have used multiple approaches to creating and updating features when missing values are present in the data, but data issues are of course not limited to just this. In some instances, you will come across features that need to be updated in some other way. Take for example the case of a column containing a monetary value. If this dataset has been imported from excel it may contain characters such as currency signs or commas that prevents pandas from reading it as numeric values.\r\n",
        "\r\n",
        "2. Bad characters\r\n",
        "For example, lets look at the data type of the RawSalary column. It's an object, although intuitively, you know that it should be numeric. So why is that?\r\n",
        "\r\n",
        "3. Bad characters\r\n",
        "Let's take a quick peek at the data. Numeric columns should not contain any non-numeric characters. So you need to remove these commas.\r\n",
        "\r\n",
        "4. Dealing with bad characters\r\n",
        "Although you want the column to be a numeric column, it is of type object, which means you can use string methods to fix this column. In this case, we want to remove all occurrences of comma. We can easily achieve this by accessing the str accessor and using the replace() method. The first argument is the string you want to replace, which is the comma, and the second argument is the string you want to replace it with, which here is an empty string, which simply means you want to remove all the commas. However, the data type of this column is still object. Now you can convert your column to the relevant type as shown here.\r\n",
        "\r\n",
        "5. Finding other stray characters\r\n",
        "But what if attempting to change the data type raises an error? This may indicate that there are additional stray characters which you didn't account for. Instead of manually searching for values with other stray characters you can use the to_numeric() function from pandas along with the errors argument. If you set the errors argument to 'coerce', Pandas will convert the column to numeric, but all values that can't be converted to numeric will be changed to NaNs, that is missing values.\r\n",
        "\r\n",
        "6. Finding other stray characters\r\n",
        "You can now use the isna() method like you did earlier to find out which values failed to parse. So it looks like we also have dollar signs. You can again use the replace() method as before to remove the dollar signs.\r\n",
        "\r\n",
        "7. Chaining methods\r\n",
        "Before you get going onto trying these for yourself, it will be useful to delve a little deeper into method chaining. If you are applying different methods or in fact the same method several times on a column, instead of assigning the result back to the column after each iteration, you can simply chain the methods, that is, call one method after the other to obtain the desired result. For example, cleaning up characters, changing the data type, normalizing the values etc. can all be achieved by simply calling the methods one after the other as seen here.\r\n",
        "\r\n",
        "8. Go ahead and fix bad characters!\r\n",
        "Now that you know how to deal with stray characters, let's put it into practice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YP4sq30Or6zA"
      },
      "source": [
        "# Dealing with stray characters (I)\r\n",
        "\r\n",
        "In this exercise, you will work with the RawSalary column of so_survey_df which contains the wages of the respondents along with the currency symbols and commas, such as \\$42,000. When importing data from Microsoft Excel, more often that not you will come across data in this form.\r\n",
        "\r\n",
        "Instructions\r\n",
        "\r\n",
        "1. Remove the commas (,) from the RawSalary column.\r\n",
        "\r\n",
        "2. Remove the dollar ($) signs from the RawSalary column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_k-EYYAsKDM"
      },
      "source": [
        "# Remove the commas in the column\r\n",
        "so_survey_df['RawSalary'] = so_survey_df['RawSalary'].str.replace(',', '')\r\n",
        "\r\n",
        "# Remove the dollar signs in the column\r\n",
        "so_survey_df['RawSalary'] = so_survey_df['RawSalary'].str.replace('$','')\r\n",
        "\r\n",
        "'''\r\n",
        "Conclusion \r\n",
        "\r\n",
        "Congratulations! Replacing/removing specific characters is a very useful skill.\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvMGMQwFtJiK"
      },
      "source": [
        "# Dealing with stray characters (II)\r\n",
        "\r\n",
        "In the last exercise, you could tell quickly based off of the df.head() call which characters were causing an issue. In many cases this will not be so apparent. There will often be values deep within a column that are preventing you from casting a column as a numeric type so that it can be used in a model or further feature engineering.\r\n",
        "\r\n",
        "One approach to finding these values is to force the column to the data type desired using pd.to_numeric(), coercing any values causing issues to NaN, Then filtering the DataFrame by just the rows containing the NaN values.\r\n",
        "\r\n",
        "Try to cast the RawSalary column as a float and it will fail as an additional character can now be found in it. Find the character and remove it so the column can be cast as a float.\r\n",
        "\r\n",
        "Instructions\r\n",
        "\r\n",
        "1. Attempt to convert the RawSalary column of so_survey_df to numeric values coercing all failures into null values.\r\n",
        "\r\n",
        "2. Find the indexes of the rows containing NaNs.\r\n",
        "\r\n",
        "3. Print the rows in RawSalary based on these indexes.\r\n",
        "\r\n",
        "4. Did you notice the pound (£) signs in the RawSalary column? Remove these signs like you did in the previous exercise.\r\n",
        "\r\n",
        "5. Convert the RawSalary column to float."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVz3Hc8NtyY3"
      },
      "source": [
        "so_survey_df.RawSalary.head()\r\n",
        "'''\r\n",
        "0          NaN\r\n",
        "1     70841.00\r\n",
        "2          NaN\r\n",
        "3     21426.00\r\n",
        "4    £41671.00\r\n",
        "Name: RawSalary, dtype: object\r\n",
        "'''\r\n",
        "\r\n",
        "# Attempt to convert the column to numeric values\r\n",
        "numeric_vals = pd.to_numeric(so_survey_df['RawSalary'], errors='coerce')\r\n",
        "numeric_vals.head()\r\n",
        "'''\r\n",
        "0        NaN\r\n",
        "1    70841.0\r\n",
        "2        NaN\r\n",
        "3    21426.0\r\n",
        "4        NaN\r\n",
        "Name: RawSalary, dtype: float64\r\n",
        "'''\r\n",
        "\r\n",
        "# Find the indexes of missing values\r\n",
        "idx = numeric_vals.isna()\r\n",
        "idx.head()\r\n",
        "'''\r\n",
        "0     True\r\n",
        "1    False\r\n",
        "2     True\r\n",
        "3    False\r\n",
        "4     True\r\n",
        "Name: RawSalary, dtype: bool\r\n",
        "'''\r\n",
        "\r\n",
        "# Print the relevant rows\r\n",
        "print(so_survey_df['RawSalary'][idx].head())\r\n",
        "'''\r\n",
        "0          NaN\r\n",
        "2          NaN\r\n",
        "4    £41671.00\r\n",
        "6          NaN\r\n",
        "8          NaN\r\n",
        "Name: RawSalary, dtype: object\r\n",
        "'''\r\n",
        "\r\n",
        "# Replace the offending characters\r\n",
        "so_survey_df['RawSalary'] = so_survey_df['RawSalary'].str.replace('£','')\r\n",
        "\r\n",
        "# Convert the column to float\r\n",
        "so_survey_df['RawSalary'] = so_survey_df['RawSalary'].astype('float')\r\n",
        "\r\n",
        "# Print the column\r\n",
        "print(so_survey_df['RawSalary'])\r\n",
        "'''\r\n",
        "<script.py> output:\r\n",
        "    0            NaN\r\n",
        "    1        70841.0\r\n",
        "    2            NaN\r\n",
        "    3        21426.0\r\n",
        "    4        41671.0\r\n",
        "    5       120000.0\r\n",
        "    6            NaN\r\n",
        "    7       250000.0\r\n",
        "    8            NaN\r\n",
        "    9            0.0\r\n",
        "    10       47904.0\r\n",
        "    11           NaN\r\n",
        "    12       95968.0\r\n",
        "    13           NaN\r\n",
        "    14         420.0\r\n",
        "    15       75000.0\r\n",
        "    16       10958.0\r\n",
        "    17       51408.0\r\n",
        "    18       72611.0\r\n",
        "    19      900000.0\r\n",
        "    20           NaN\r\n",
        "    21       30000.0\r\n",
        "    22           NaN\r\n",
        "    23       44000.0\r\n",
        "    24       60000.0\r\n",
        "    25           NaN\r\n",
        "    26       80000.0\r\n",
        "    27           NaN\r\n",
        "    28           NaN\r\n",
        "    29           NaN\r\n",
        "             ...    \r\n",
        "    969      37200.0\r\n",
        "    970      79973.0\r\n",
        "    971      73428.0\r\n",
        "    972      56298.0\r\n",
        "    973      17628.0\r\n",
        "    974     125000.0\r\n",
        "    975          NaN\r\n",
        "    976          NaN\r\n",
        "    977          NaN\r\n",
        "    978      75000.0\r\n",
        "    979       6576.0\r\n",
        "    980          NaN\r\n",
        "    981      60000.0\r\n",
        "    982      80000.0\r\n",
        "    983      90000.0\r\n",
        "    984      70000.0\r\n",
        "    985      39648.0\r\n",
        "    986      99967.0\r\n",
        "    987       2352.0\r\n",
        "    988      50448.0\r\n",
        "    989          NaN\r\n",
        "    990          NaN\r\n",
        "    991      55562.0\r\n",
        "    992          NaN\r\n",
        "    993      30000.0\r\n",
        "    994          NaN\r\n",
        "    995      58746.0\r\n",
        "    996      55000.0\r\n",
        "    997          NaN\r\n",
        "    998    1000000.0\r\n",
        "    Name: RawSalary, Length: 999, dtype: float64\r\n",
        "'''\r\n",
        "'''\r\n",
        "Conclusion\r\n",
        "\r\n",
        "Nicely done! Remember that even after removing all the relevant characters, you still need \r\n",
        " to change the type of the column to numeric if you want to plot these continuous values.\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-8vK_9qxG3F"
      },
      "source": [
        "# Method chaining\r\n",
        "\r\n",
        "When applying multiple operations on the same column (like in the previous exercises), you made the changes in several steps, assigning the results back in each step. However, when applying multiple successive operations on the same column, you can \"chain\" these operations together for clarity and ease of management. This can be achieved by calling multiple methods sequentially:\r\n",
        "\r\n",
        "```\r\n",
        "# Method chaining\r\n",
        "df['column'] = df['column'].method1().method2().method3()\r\n",
        "\r\n",
        "# Same as \r\n",
        "df['column'] = df['column'].method1()\r\n",
        "df['column'] = df['column'].method2()\r\n",
        "df['column'] = df['column'].method3()\r\n",
        "```\r\n",
        "In this exercise you will repeat the steps you performed in the last two exercises, but do so using method chaining.\r\n",
        "\r\n",
        "Instructions\r\n",
        "\r\n",
        "1. Remove the commas (,) from the RawSalary column of so_survey_df.\r\n",
        "\r\n",
        "2. Remove the dollar ($) signs from the RawSalary column.\r\n",
        "\r\n",
        "3. Remove the pound (£) signs from the RawSalary column.\r\n",
        "\r\n",
        "4. Convert the RawSalary column to float."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loqAgNqSzqg7"
      },
      "source": [
        "# Use method chaining\r\n",
        "so_survey_df['RawSalary'] = so_survey_df['RawSalary']\\\r\n",
        "                              .str.replace(',', '')\\\r\n",
        "                              .str.replace('$','')\\\r\n",
        "                              .str.replace('£','')\\\r\n",
        "                              .astype('float')\r\n",
        " \r\n",
        "# Print the RawSalary column\r\n",
        "print(so_survey_df['RawSalary'])\r\n",
        "'''\r\n",
        "<script.py> output:\r\n",
        "    0            NaN\r\n",
        "    1        70841.0\r\n",
        "    2            NaN\r\n",
        "    3        21426.0\r\n",
        "    4        41671.0\r\n",
        "    5       120000.0\r\n",
        "    6            NaN\r\n",
        "    7       250000.0\r\n",
        "    8            NaN\r\n",
        "    9            0.0\r\n",
        "    10       47904.0\r\n",
        "    11           NaN\r\n",
        "    12       95968.0\r\n",
        "    13           NaN\r\n",
        "    14         420.0\r\n",
        "    15       75000.0\r\n",
        "    16       10958.0\r\n",
        "    17       51408.0\r\n",
        "    18       72611.0\r\n",
        "    19      900000.0\r\n",
        "    20           NaN\r\n",
        "    21       30000.0\r\n",
        "    22           NaN\r\n",
        "    23       44000.0\r\n",
        "    24       60000.0\r\n",
        "    25           NaN\r\n",
        "    26       80000.0\r\n",
        "    27           NaN\r\n",
        "    28           NaN\r\n",
        "    29           NaN\r\n",
        "             ...    \r\n",
        "    969      37200.0\r\n",
        "    970      79973.0\r\n",
        "    971      73428.0\r\n",
        "    972      56298.0\r\n",
        "    973      17628.0\r\n",
        "    974     125000.0\r\n",
        "    975          NaN\r\n",
        "    976          NaN\r\n",
        "    977          NaN\r\n",
        "    978      75000.0\r\n",
        "    979       6576.0\r\n",
        "    980          NaN\r\n",
        "    981      60000.0\r\n",
        "    982      80000.0\r\n",
        "    983      90000.0\r\n",
        "    984      70000.0\r\n",
        "    985      39648.0\r\n",
        "    986      99967.0\r\n",
        "    987       2352.0\r\n",
        "    988      50448.0\r\n",
        "    989          NaN\r\n",
        "    990          NaN\r\n",
        "    991      55562.0\r\n",
        "    992          NaN\r\n",
        "    993      30000.0\r\n",
        "    994          NaN\r\n",
        "    995      58746.0\r\n",
        "    996      55000.0\r\n",
        "    997          NaN\r\n",
        "    998    1000000.0\r\n",
        "    Name: RawSalary, Length: 999, dtype: float64\r\n",
        "'''\r\n",
        "'''\r\n",
        "Conclusion\r\n",
        "\r\n",
        "Great job! Custom functions can be also used when method chaining using the .apply() method.\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}